{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Lane Lines on the Road "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some OpenCV functions that might be useful:**\n",
    "\n",
    "`cv2.inRange()` for color selection  \n",
    "`cv2.fillPoly()` for regions selection  \n",
    "`cv2.line()` to draw lines on an image given endpoints  \n",
    "`cv2.addWeighted()` to coadd / overlay two images\n",
    "`cv2.cvtColor()` to grayscale or change color\n",
    "`cv2.imwrite()` to output images to file  \n",
    "`cv2.bitwise_and()` to apply a mask to an image\n",
    "\n",
    "**Check out the OpenCV documentation to learn about these and discover even more awesome functionality!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "slope_left_prior = -0.5\n",
    "slope_right_prior = 0.5\n",
    "x_left_prior = 0\n",
    "y_left_prior = 0\n",
    "x_right_prior = 0\n",
    "y_right_prior = 0\n",
    "\n",
    "def grayscale(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=10):\n",
    "    global slope_left_prior, slope_right_prior, x_left_prior, y_left_prior, x_right_prior, y_right_prior\n",
    "    \n",
    "    #set initial parameters for the line\n",
    "    slope_left = []\n",
    "    slope_right = []\n",
    "    x_left_int = []\n",
    "    y_left_int = []\n",
    "    x_right_int = []\n",
    "    y_right_int = []\n",
    "   \n",
    "    for line in lines:\n",
    "        for cord in line:\n",
    "            if cord[2]-cord[0] != 0:\n",
    "                slope = (float(cord[3]-cord[1]))/(float(cord[2]-cord[0]))\n",
    "                if -0.8 < slope < -0.3:\n",
    "                    slope_left.append(slope) \n",
    "                    y_left_int.append((cord[1]+cord[3])/2)\n",
    "                    x_left_int.append((cord[0]+cord[2])/2)\n",
    "                if 0.3 < slope < 0.8:\n",
    "                    slope_right.append(slope) \n",
    "                    y_right_int.append((cord[1]+cord[3])/2)\n",
    "                    x_right_int.append((cord[0]+cord[2])/2)\n",
    "    \n",
    "    #use the mean of the slopes to extrapolate the line \n",
    "    if len(slope_left) == 0:\n",
    "        slope_left_mean = slope_left_prior\n",
    "        x_left_mean = x_left_prior\n",
    "        y_left_mean = y_left_prior\n",
    "    else:\n",
    "        slope_left_mean = sum(slope_left)/float(len(slope_left))\n",
    "        if slope_left_prior * 1.25 < slope_left_mean < slope_left_prior * 0.75:\n",
    "            slope_left_mean = 0.9*slope_left_mean + 0.1*slope_left_prior\n",
    "        else:\n",
    "            slope_left_mean = 0.1*slope_left_mean + 0.9*slope_left_prior\n",
    "        slope_left_prior = slope_left_mean\n",
    "        x_left_mean = sum(x_left_int)/float(len(x_left_int))\n",
    "        y_left_mean = sum(y_left_int)/float(len(y_left_int))\n",
    "        x_left_prior = x_left_mean\n",
    "        y_left_prior = y_left_mean\n",
    "    \n",
    "    if len(slope_right) == 0:\n",
    "        slope_right_mean = slope_right_prior\n",
    "        x_right_mean = x_right_prior\n",
    "        y_right_mean = y_right_prior\n",
    "    else:\n",
    "        slope_right_mean = sum(slope_right)/float(len(slope_right))\n",
    "        if slope_right_prior * 0.75 < slope_right_mean < slope_right_prior * 1.25:\n",
    "            slope_right_mean = 0.9*slope_right_mean + 0.1*slope_right_prior\n",
    "        else:\n",
    "            slope_right_mean = 0.1*slope_right_mean + 0.9*slope_right_prior\n",
    "        slope_right_prior = slope_right_mean\n",
    "        x_right_mean = sum(x_right_int)/float(len(x_right_int))\n",
    "        y_right_mean = sum(y_right_int)/float(len(y_right_int))\n",
    "        x_right_prior = x_right_mean\n",
    "        y_right_prior = y_right_mean\n",
    "    \n",
    "    x1_left = int(x_left_mean - (y_left_mean - img.shape[0])/slope_left_mean)\n",
    "    x2_left = int((region_of_interest_y - img.shape[0])/slope_left_mean + x1_left)\n",
    "    x1_right = int(x_right_mean - (y_right_mean - img.shape[0])/slope_right_mean)\n",
    "    x2_right = int((region_of_interest_y - img.shape[0])/slope_right_mean + x1_right)\n",
    "    \n",
    "    cv2.line(img, (x1_left, img.shape[0]), (x2_left, region_of_interest_y), color, thickness)\n",
    "    cv2.line(img, (x1_right, img.shape[0]), (x2_right, region_of_interest_y), color, thickness)\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((*img.shape, 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "def weighted_img(img, initial_img, α, β, λ):\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test parameters\n",
    "gaussian_blur_kernel_size = 5\n",
    "canny_low_threshold = 50\n",
    "canny_high_threshold = 150\n",
    "region_of_interest_y = 330\n",
    "region_of_interest_x_left = 450\n",
    "region_of_interest_x_right = 490\n",
    "hough_lines_rho = 2\n",
    "hough_lines_theta = np.pi/180\n",
    "hough_lines_threshold = 20\n",
    "hough_lines_min_line_length = 40\n",
    "hough_lines_max_line_gap = 5\n",
    "weighted_img_α = 1.\n",
    "weighted_img_β = 1.\n",
    "weighted_img_λ = 0.\n",
    "\n",
    "# Test function\n",
    "def process_image(image):\n",
    "    gray = grayscale(image)\n",
    "    blur_gray = gaussian_blur(gray, gaussian_blur_kernel_size)\n",
    "    edges = canny(blur_gray, canny_low_threshold, canny_high_threshold)\n",
    "    region_of_interest_vertices = np.array([[(0,image.shape[0]),(region_of_interest_x_left, region_of_interest_y), \n",
    "                                             (region_of_interest_x_right, region_of_interest_y), \n",
    "                                             (image.shape[1],image.shape[0])]], dtype=np.int32)\n",
    "    masked_edges = region_of_interest(edges, region_of_interest_vertices)\n",
    "    line = hough_lines(masked_edges, hough_lines_rho, hough_lines_theta, hough_lines_threshold, \n",
    "                       hough_lines_min_line_length, hough_lines_max_line_gap)\n",
    "    result = weighted_img(line, image, weighted_img_α, weighted_img_β, weighted_img_λ)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p_solidWhiteCurve.jpg',\n",
       " 'p_solidWhiteRight.jpg',\n",
       " 'p_solidYellowCurve.jpg',\n",
       " 'p_solidYellowCurve2.jpg',\n",
       " 'p_solidYellowLeft.jpg',\n",
       " 'p_whiteCarLaneSwitch.jpg',\n",
       " 'solidWhiteCurve.jpg',\n",
       " 'solidWhiteRight.jpg',\n",
       " 'solidYellowCurve.jpg',\n",
       " 'solidYellowCurve2.jpg',\n",
       " 'solidYellowLeft.jpg',\n",
       " 'whiteCarLaneSwitch.jpg']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"test_images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_solidWhiteCurve = process_image(mpimg.imread('test_images/solidWhiteCurve.jpg'))\n",
    "mpimg.imsave('test_images/p_solidWhiteCurve.jpg', p_solidWhiteCurve)\n",
    "p_solidWhiteRight = process_image(mpimg.imread('test_images/solidWhiteRight.jpg'))\n",
    "mpimg.imsave('test_images/p_solidWhiteRight.jpg', p_solidWhiteRight)\n",
    "p_solidYellowCurve = process_image(mpimg.imread('test_images/solidYellowCurve.jpg'))\n",
    "mpimg.imsave('test_images/p_solidYellowCurve.jpg', p_solidYellowCurve)\n",
    "p_solidYellowCurve2 = process_image(mpimg.imread('test_images/solidYellowCurve2.jpg'))\n",
    "mpimg.imsave('test_images/p_solidYellowCurve2.jpg', p_solidYellowCurve2)\n",
    "p_solidYellowLeft = process_image(mpimg.imread('test_images/solidYellowLeft.jpg'))\n",
    "mpimg.imsave('test_images/p_solidYellowLeft.jpg', p_solidYellowLeft)\n",
    "p_whiteCarLaneSwitch = process_image(mpimg.imread('test_images/whiteCarLaneSwitch.jpg'))\n",
    "mpimg.imsave('test_images/p_whiteCarLaneSwitch.jpg', p_whiteCarLaneSwitch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video white.mp4\n",
      "[MoviePy] Writing video white.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 221/222 [00:02<00:00, 97.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: white.mp4 \n",
      "\n",
      "CPU times: user 2.36 s, sys: 491 ms, total: 2.85 s\n",
      "Wall time: 2.47 s\n"
     ]
    }
   ],
   "source": [
    "white_output = 'white.mp4'\n",
    "clip1 = VideoFileClip('solidWhiteRight.mp4')\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"white.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video yellow.mp4\n",
      "[MoviePy] Writing video yellow.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 681/682 [00:07<00:00, 93.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: yellow.mp4 \n",
      "\n",
      "CPU times: user 7.75 s, sys: 1.52 s, total: 9.26 s\n",
      "Wall time: 7.64 s\n"
     ]
    }
   ],
   "source": [
    "yellow_output = 'yellow.mp4'\n",
    "clip2 = VideoFileClip('solidYellowLeft.mp4')\n",
    "yellow_clip = clip2.fl_image(process_image)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"yellow.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Where will your current algorithm be likely to fail?\n",
    "1. My current algorithm has a set region of interest. If the camera angle changes, the region has to be updated accordingly. That also means this will not work when there are hills or sharp turns. \n",
    "2. The slopes and coordinates setting were trial and error. They work for the two videos and for most of the challenge below. But it is not a robust solution. \n",
    "3. Actually, all test parameters in the third block are not robust enough for a work-for-all solution.\n",
    "4. No robust distortion correction or color thresholding.\n",
    "\n",
    "###### How could you imagine making your algorithm better / more robust?\n",
    "Having a more robust definition for region of interest, range for test parameters, slope and coordinate and better distortion correction and color threshold will improve the current algorithm. There are a couple of frames where the current code doesn't work well for the optional challenge, like when the car drove onto the patch of road with lighter colors. I believe this is covered in the later modules. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Optional Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video extra.mp4\n",
      "[MoviePy] Writing video extra.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [00:05<00:00, 45.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: extra.mp4 \n",
      "\n",
      "CPU times: user 4.97 s, sys: 1.25 s, total: 6.22 s\n",
      "Wall time: 6.28 s\n"
     ]
    }
   ],
   "source": [
    "region_of_interest_y = 450\n",
    "region_of_interest_x_left = 575\n",
    "region_of_interest_x_right = 750\n",
    "challenge_output = 'extra.mp4'\n",
    "clip2 = VideoFileClip('challenge.mp4')\n",
    "challenge_clip = clip2.fl_image(process_image)\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)\n",
    "#challenge_clip = clip2.fl_image(plt.imshow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"extra.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
